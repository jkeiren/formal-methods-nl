\documentclass[sigplan,10pt,noacm]{acmart}
\settopmatter{printfolios=false,printccs=false,printacmref=false}

\acmConference{A Research Agenda for Formal Methods in The Netherlands}%
  {September 3--4, 2018}%
  {Lorentz Center, Leiden, The Netherlands}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%\bibliographystyle{ACM-Reference-Format}
\bibliographystyle{abbrv}


\setcopyright{none}

\usepackage{csquotes}

\begin{document}

\title{Formal Methods for Better Software in Computational Science}
\author{Anna-Lena Lamprecht}

\affiliation{
  \institution{Universiteit Utrecht}
  \country{The Netherlands}
}
\email{a.l.lamprecht@uu.nl}
\maketitle


\section{Introduction}

%Industry provides many areas of application for formal methods. Hardware and software in, for example, the automotive and medical sector and for autonomous and mobile applications regularly constitute critical systems that must be ensured to fulfill certain constraints of correctness, robustness, timeliness, etc. Many formal method techniques and frameworks have found their way from theory into industrial practice and are successfuly used in this context.

Science across all domains is increasingly data-driven and computational, and thus the \textbf{correctness of research software} becomes increasingly critical for the validity of scientific results. Yet formal methods and software quality assurance in general have not received great attention in this context in the past.

\textbf{Software engineering practices} in science can differ widely from what is common in industry. In a recent review article \cite{HeaCar2015}, Heaton et al. report, for example, that scientific software developers generally do not use a formal software development methodolody, do not produce proper requirements specifications, and do not treat design as a distinct step in the development process. Furthermore, they find that the effectiveness of the testing practices currently used by scientific software developers is limited, that \textbf{testing is more complicated} for scientific development than traditional software development since the correct results are often unknown, and similarly that the lack of suitable test oracles or comparable software makes validating scientific software difficult. There are many ways that defects can enter software, but scientists often suspect that any problems in the result of software result from scientific theory rather than from implementation. Experimental validation is often impractical because developers lack the information they would prefer to use to validate the software. 

Moreover, even true wet lab scientists are often not only end users of software developed by more or less professional software engineers. Since research topics are often extremely specific, software for the specific purpose is frequently not readily available and so scientists \textbf{need to develop software themselves}. In many cases this concerns just \enquote{glue code} to connect existing components and automate the processing of large numbers of data sets, but nevertheless correctness is important. Generally, however, scientists (many of them \textbf{self-taught programmers}) do not test systematically, let alone verify their programs formally. Code is often intended to be \enquote{Kleenex software} for one-time use, with the developer being its only user and publishing the results being the only purpose that matters, so there is no incentive for putting effort into further quality considerations. Of course, it happens frequently that the software is nevertheless used again later on, modified and extended, but never tested, validated, verified and released properly.

There are many possibilities how formal methods can help to address these issues. In the following I outline possible applications in the area of scientific workflows and in relation to dynamically typed languages like Python and R, which relate to own previous work and experiences with scientists from different domains. 

\section{Scientific Workflows}

The concept of \textbf{scientific workflows} has become popular in the scientific community over the last years \cite{AtGeMT2017}. Workflows provide a systematic way of describing data-intensive computational processes, and provide an interface between domain specialists and computing infrastructures. 
Several workflow management systems exist that support scientists in their construction and execution, often making use of graphical representations of the workflow models. Historically grown and driven by practice, a variety of \textbf{workflow languages} exists, but slowly the community is progressing to standardized scientific workflow languages, with the Common Workflow Language (CWL) and the Workflow Description Language (WDL) currently enjoying great popularity. 

Being inherently component-oriented and model-driven, scientific workflows are an almost natural target for the application of \textbf{model-based formal methods}, such as model checking and synthesis \cite{LaMaSt2008,Lampre2013}.
\textbf{Model checking} can in this context act as a \enquote{spell checker}, monitoring the workflow under development and alerting the user in case it violates certain constraints. These can be generic, rather technical issues like mismatching data types (e.g., a certain component is not able to work on the data format provided by its predecessor) and other static analyses, or more domain-specific, semantic constraints that express knowledge about the workflow's purpose or rules of best practice, like, for example, that all experimental data will eventually be stored in the project repository, that unexpected analysis results will always lead to an alert, or chargeable services will not be called before permission is given by the user.

\textbf{Synthesis} goes a step further: Instead of using constraints only to check if a workflow is correct, it starts with constraints and automatically assembles a workflow that is thus correct by construction. In addition to general constraints like those sketched above, this requires the user to express their intents about the workflow in a suitable way. Intents like \enquote{Take a BLAST result as input and finally produce a phylogenetic tree.} or \enquote{Having a single (genetic) sequence, I want to find similar sequences and get information about their evolutionary relationship.} can be expressed in formal logic and processed by a synthesis framework.

The application of model checking and synthesis as sketched above requires to tailor methods and frameworks to the specifics of the domain, making use of \textbf{domain-specific ontologies} that facilitate working with a controlled vocabulary at a level of abstraction that feels natural to the user. In particular the bioinformatics community has made a lot of progress in this regard in the last years, with the EDAM ontology providing a rich domain-specific vocabulary for the description of bioinformatics operations, data types and formats, from which tool annotation and constraint-driven workflow synthesis are straightforward next steps \cite{PaLaIS2018}. 

Future work in this area will in the first place have to address issues of \textbf{usability} (accessible specification languages, usable tools, integration into the scientists' software ecosystems, high-quality domain models) and \textbf{scalability} (mitigation of state explosion effects, scaling up ontological modelling and semantic annotation) in collaboration with the targeted application domains. 


\section{Python and R}

Formally trained computer scientists are often irritated by the fact that Python and GNU R appear to be the \textbf{most popular} languages among data scientists of all disciplines. They are regarded easy to learn, but most importantly in practice, large amounts of libraries are available for these languages that readily provide frequently needed functionality. That is, they are often simply the fastest means to get data analyzed (and results published). Considerations about correctness, code quality and maintainability come second.

Python and R are \textbf{dynamically typed languages}, that is, variables are declared without a concrete type, and get assigned concrete types only at runtime. Such code is usually faster to write, but when a program gets more complex, runtime errors caused by mismatching data types are the norm and can be difficult to fix (especially by programmers without much experience).
Even worse, it can happen that type mismatches remain undetected and lead to wrong results: Many libraries like those mentioned above transparently perform type casts to make programming simpler for the user, by \enquote{guessing} the correct type. Not suprisingly, sometimes this goes wrong, and suddenly the data has changed, leading to alternative results, but no runtime error or warning alerts the user. If the obtained values are really far away from the expected, the scientist might get suspicious, but when they remain in feasible ranges or even give a sensational result, they just go through to publication.

As of version 3.6 Python includes a \textbf{static type checker} to support programmers to catch common type-related errors already while coding. It remains to be seen, however, if this feature will be taken up by the scientific community. Likely programming in Python, R and similar languages would benefit greatly from IDEs that are aware of \textbf{domain-specific type systems} related to the domain models sketched above, or even \textbf{dependent types}~\cite{wouter}, and based on that provide support to \textbf{diagnose and fix type errors} as described in~\cite{jur}.


\section{Conclusion}

In the development of scientific software more attention needs to be devoted to correctness and other aspects of software quality. I am convinced that formal methods can make a great contribution there, up to providing intuitive, user-level frameworks for correct-by-construction development of scientific software. In particular, this will require close collaboration with scientists from the targeted domains in order to adapt the general methods to their concrete needs and to capture and formalize the required domain knowledge adequately.
The Netherlands has strong and internationally recognized communities in e-Science and Semantic Web research, so there is a lot of potential for joint efforts and impact in this area. 


\bibliography{references}

\end{document}
