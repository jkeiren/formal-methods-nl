%% For double-blind review submission, w/o CCS and ACM Reference (max submission space)
\documentclass[sigplan,10pt]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For double-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,10pt,review,anonymous]{acmart}\settopmatter{printfolios=true}
%% For single-blind review submission, w/o CCS and ACM Reference (max submission space)
%\documentclass[sigplan,10pt,review]{acmart}\settopmatter{printfolios=true,printccs=false,printacmref=false}
%% For single-blind review submission, w/ CCS and ACM Reference
%\documentclass[sigplan,10pt,review]{acmart}\settopmatter{printfolios=true}
%% For final camera-ready submission, w/ required CCS and ACM Reference
%\documentclass[sigplan,10pt]{acmart}\settopmatter{}


%% Conference information
%% Supplied to authors by publisher for camera-ready submission;
%% use defaults for review submission.
\acmConference[FM-NL'18]{Lorentz Symposium on a Research Agenda for Formal Methods in the Netherlands}{September 03---04, 2018}{Leiden, The Netherlands}
\acmYear{2018}
\acmISBN{} % \acmISBN{978-x-xxxx-xxxx-x/YY/MM}
\acmDOI{} % \acmDOI{10.1145/nnnnnnn.nnnnnnn}
\startPage{1}

%% Copyright information
%% Supplied to authors (based on authors' rights management selection;
%% see authors.acm.org) by publisher for camera-ready submission;
%% use 'none' for review submission.
\setcopyright{none}
%\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\copyrightyear{2017}           %% If different from \acmYear

%% Bibliography style
\bibliographystyle{ACM-Reference-Format}
%% Citation style
%\citestyle{acmauthoryear}  %% For author/year citations
%\citestyle{acmnumeric}     %% For numeric citations
%\setcitestyle{nosort}      %% With 'acmnumeric', to disable automatic
                            %% sorting of references within a single citation;
                            %% e.g., \cite{Smith99,Carpenter05,Baker12}
                            %% rendered as [14,5,2] rather than [2,5,14].
%\setcitesyle{nocompress}   %% With 'acmnumeric', to disable automatic
                            %% compression of sequential references within a
                            %% single citation;
                            %% e.g., \cite{Baker12,Baker14,Baker16}
                            %% rendered as [2,3,4] rather than [2-4].


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Note: Authors migrating a paper from traditional SIGPLAN
%% proceedings format to PACMPL format must update the
%% '\documentclass' and topmatter commands above; see
%% 'acmart-pacmpl-template.tex'.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%% Some recommended packages.
\usepackage{booktabs}   %% For formal tables:
                        %% http://ctan.org/pkg/booktabs
\usepackage{subcaption} %% For complex figures with subfigures/subcaptions
                        %% http://ctan.org/pkg/subcaption


\begin{document}

%% Title information
\title[]{More Code, More Quantities}         %% [Short Title] is optional;
                                        %% when present, will be used in
                                        %% header instead of Full Title.
%%\titlenote{with title note}             %% \titlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'
%% \subtitle{Subtitle}                     %% \subtitle is optional
%% \subtitlenote{with subtitle note}       %% \subtitlenote is optional;
                                        %% can be repeated if necessary;
                                        %% contents suppressed with 'anonymous'


%% Author information
%% Contents and number of authors suppressed with 'anonymous'.
%% Each author should be introduced by \author, followed by
%% \authornote (optional), \orcid (optional), \affiliation, and
%% \email.
%% An author may have multiple affiliations and/or emails; repeat the
%% appropriate command.
%% Many elements are not rendered, but should be provided for metadata
%% extraction tools.

%% Author with two affiliations and emails.
\author{Joost-Pieter Katoen}
%% \authornote{with author2 note}          %% \authornote is optional;
                                        %% can be repeated if necessary
\orcid{nnnn-nnnn-nnnn-nnnn}             %% \orcid is optional
\affiliation{
  \position{RWTH Aachen University, Software Modeling and Verification}
%%  \department{Dept. of Computer Science}             %% \department is recommended
%%  \institution{}           %% \institution is required
%%  \streetaddress{Ahornstrasse 55}
  \city{Aachen}
%%  \state{State2a}
  \postcode{52056}
  \country{Germany}                   %% \country is recommended
}
\email{}         %% \email is recommended
\affiliation{
  \position{University of Twente, Formal Methods and Tools}
%%  \department{Dept. of Computer Science}             %% \department is recommended
%%  \institution{}           %% \institution is required
%%  \streetaddress{Street3b Address2b}
  \city{Enschede}
%%  \state{State2b}
  \postcode{7500AE}
  \country{The Netherlands}                   %% \country is recommended
}
\email{katoen@cs.rwth-aachen.de, katoen@utwente.nl}         %% \email is recommended


%% Abstract
%% Note: \begin{abstract}...\end{abstract} environment must come
%% before \maketitle command
\begin{abstract}
Formal methods are pretty strong in the Netherlands. It is however primarily focused on correctness in the Boolean sense: an artefact (being it a program or a system) is correct or not. Without doubt correctness is of pivotal importance, but in my view we should be ready to make a paradigm shift to a more quantitative setting. Big data, machine learning, robots (to mention a few) rapidly are becoming dominant for programs and (safety-critical) ICT systems. They come with a high degree of uncertainty. Reasoning about this requires that formal methodists leave the Boolean territory --- \emph{it is quantitative reasoning that is sought for!}
In addition, model-based techniques prevail in Dutch formal methods. This contrasts the international trend  where more and more emphasis is put on (continuously) verifying software at the code level. It is time that Dutch formal methodists take software more seriously --- \emph{it is software in cars, washing machines, and aerospace systems that becomes the bottleneck!}
\end{abstract}


%% 2012 ACM Computing Classification System (CSS) concepts
%% Generate at 'http://dl.acm.org/ccs/ccs.cfm'.
\begin{CCSXML}
<ccs2012>
<concept>
<concept_id>10011007.10011006.10011008</concept_id>
<concept_desc>Software and its engineering~General programming languages</concept_desc>
<concept_significance>500</concept_significance>
</concept>
<concept>
<concept_id>10003456.10003457.10003521.10003525</concept_id>
<concept_desc>Social and professional topics~History of programming languages</concept_desc>
<concept_significance>300</concept_significance>
</concept>
</ccs2012>
\end{CCSXML}

\ccsdesc[500]{Software and its engineering~General programming languages}
\ccsdesc[300]{Social and professional topics~History of programming languages}
%% End of generated code


%% Keywords
%% comma separated list
%%\keywords{keyword1, keyword2, keyword3}  %% \keywords are mandatory in final camera-ready submission


%% \maketitle
%% Note: \maketitle command must come after title commands, author
%% commands, abstract environment, Computing Classification System
%% environment and commands, and keywords command.
\maketitle

\section{Formal Verification}

Key considerations for computer programs are whether they will terminate, and if so, whether the result of their computation is correct.
The fundamental questions ``does a computer program terminate?'' and ``does a computer program work as expected?'' are core --- if not the most important --- research topics in program analysis ever since Turing's seminal paper on providing a program proof in 1949.
As hard guarantees cannot be achieved using common techniques such as peer review (aka: manual inspection), extensive simulation and testing, more rigorous means are needed. 
This is where \emph{formal verification techniques} enter the scene.
They strive for establishing that a program is correct with respect to a given specification, a precise description of the input-output behaviour of the program.
This is a challenge as proving program correctness is undecidable in general.
Main techniques are deductive techniques \`a la Floyd-Hoare and model checking. 

Model checking is a successful technique for finite-state systems making it very popular for checking hardware; e.g., the temporal logic PSL is an international standard for formal hardware specifications.
The state-of-the art in \emph{software verification} is to use a carefully balanced mixture of deductive techniques (to support computing weakest preconditions), model checking, program analysis, and satisfiability-modulo theory (SMT) techniques~\cite{DBLP:journals/csur/JhalaM09}.
Powerful abstraction-refinement techniques enable the automated verification of a large class of programs. 

\section{The Rise of Software Verification}

Formal verification has been adopted by the main software companies.
On the world-wide level, Microsoft uses program verification to find bugs (or better: show their absence) in device-driver software, Facebook provides their programmers with tools employing lightweight formal verification to improve their software quality by tracing memory leaks and null pointer dereferencing, and Amazon web services attacks security leaks with formal verification~\cite{DBLP:conf/cav/Cook18}.
Microsoft, Google, Amazon, and Facebook all provide funding possibilities for applying and further developing formal verification.
Facebook's continuous verification program to boost the scalability of formal verification is an interesting example of this~\cite{DBLP:conf/lics/OHearn18}.

Also in Germany, formal verification is (finally) on the agenda of some major companies.
This includes car manufacturers such as BMW and Mercedes, but also companies such as Bosch and Siemens.
In close collaboration with --- and completely funded by --- Siemens we have recently finished building an IC3-based software model checker for C programs in the last five years~\cite{DBLP:conf/spin/0001PNNK18}. 
Although it is applicable to general C programs, it is tailored to programmable logic controllers (PLCs) with specific support for arrays, floating points (for treating trigonometric functions occurring in motor control), and bit-vector analysis. 
The underlying technology is based on aggressive abstraction (IC3 and generalization), SMT, and deductive techniques for computing weakest preconditions.
Together with --- and fully funded by --- Ford motor company (in Germany and the USA), we are currently applying software verification to C code that is automatically generated from Simulink~\cite{DBLP:conf/fm/BergerKAWR18}. 

\section{More Programs, Less Models}

I observe two trends.
The first trend: software companies have adopted formal verification to quite some extent.
They have entire research groups, bought out famous academics in the field, and invest substantial amounts in further developing the field.
And is not safety-critical software per se that is focused on.
\emph{It seems that Dutch software industry does not follow this international trend at all.}
Why is this? Is it their ignorance? Is software development not major enough? 

Or does it have perhaps to do with the second trend: there is a clear shift from model-based to code-based analysis.
Whereas until about a a decade ago, model-based verification (UML, AADL, process algebra, etc.) was prevailing, software verification --- directly proving properties on the code --- is taken over.
\emph{It seems that Dutch formal methodists do not follow this trend.}
There are a few Dutch groups doing (excellent) research on (semi-)automated program verification, but it seems (to me) that model-based techniques are still in their majority.
Why? Is this because of the strong Dutch tradition on model-based formalisms such as process algebras? 
Or are we more system oriented rather than software oriented? 
Or is it because in the Netherlands the primary use of software is in trading and finance, and not in industry? 

\section{The Rise of Uncertainty}

Uncertainty is nowadays more and more pervasive in computer science. 
It is important both in big data and at the level of events and control. 
Applications have to treat lots of data, often from unreliable sources such as noisy sensors and untrusted web pages. 
Data may also be subject to continuous changes, may come in different formats, and is often incomplete.
Systems have to deal with unpredictable and sometimes hostile environments. 
A different, also inevitable, kind of uncertainty arises from abstractions in system models focusing on the
control of events.

Probabilistic modelling and randomization are key techniques for dealing with uncertainty.
Many trends witness this. 
Real-world modelling in planning is advancing by probabilistic programs describing complex Bayesian networks. 
In security, hostile environments are often captured by probabilistic adversaries. 
Probabilistic databases deal with uncertain data by associating probabilities to the possible worlds. In systems verification, probabilistic model checking has emerged as a key technique allowing for correctness checking and performance analysis. 
Similar developments take place in logic and game theory.
The pervasiveness of uncertainty urges to make substantial enhancements in probabilistic modelling and reasoning so as to understand, reason about, and master uncertainty.
\emph{This requires a paradigm shift from reasoning about Boolean correctness --- a system is correct or not --- to a more quantitative notion.}
This is in line with Henzinger's convincing arguments of a few years ago~\cite{DBLP:journals/ife/Henzinger13}.
With the advent of machine learning, big data, and robotics, I feel that such shift is more needed than ever.

\section{More Quantities, Less Booleans} 

With the rapidly growing application of machine learning in e.g., self--driving cars, the need for verified guarantees against potentially fatal accidents is self--evident. 
To substantiate this, let me quote the U.S.\ government report \emph{``Preparing for the Future of Artificial Intelligence''}:
\begin{quote}
{If practitioners cannot achieve justified confidence that a system is safe and controllable, so that deploying the system does not create an unacceptable risk of serious negative consequences, then the system cannot and should not be deployed.}
\end{quote}
%%
Machine learning naturally cannot guarantee safe behavior. 
However, growing application areas such as autonomous driving, require the exclusion or likely avoidance of unsafe behaviors. 
Formal verification has the potential to indicate confidence in system behaviors obtained from machine learning. 
Vice versa, leveraging the capabilities of machine learning to quickly assess large data sets may help to enable verification for more realistic systems.
Machine learning typically obtains results but provides no evidence about this.\footnote{The NIPS 2017 test-of-time award presentation claims that \emph{machine learning has become alchemy}.}
Formal verification techniques such as counterexample generation have the potential to obtain some explainability.
A recent list of challenges on the edge of machine learning and formal verification~\cite{DBLP:journals/dagstuhl-reports/JansenKKK18} includes  a.o.\ safety verification of deep neural networks, formal program synthesis and analysis using machine learning, explainable AI, machine learning in motion planning, and guarantees on reinforcement learning in verification.
%%
%Let me briefly illustrate this by means of probabilistic programming, a field that is attracting more and more attention~\footnote{The first international conference on Probabilistic Programming takes place in October 2018.}
%Probabilistic programs steer autonomous robots --- as programs controlling intelligent systems such as robots contain machine-learning routines operating with a probabilistic model of the robot's environment --- are at the heart of security mechanisms, and are used in AI to infer statistical conclusions about huge amounts of uncertain data. 
%Do these programs work safely? Do they compute what one expects them to do? With what precision? Fast enough? Do they terminate at all? With what probability? How much resources do they consume? 
%Formal verification techniques have the potential to answer these vital questions.
%With hard guarantees.
%So far, simulative analysis techniques are (heavily) dominating the analysis of such programs.
\emph{Evidently, quantities is what is sought for; it is no longer sufficient to treat correctness in a Boolean, absolute sense.}

%% Bibliography
\bibliography{literature}

\end{document}
